---
layout: practice
author: Alex Serban, Koen van der Blom, Joost Visser
name: Use Privacy-Preserving ML Techniques
category: Data
index: 7
unique_id: privacy_preserving
difficulty: na
references: [TTAID]
comments: True
description:
image: #
photocredit: #

intent: Provide privacy protection for people whose data is used in developing your ML application #
motivation: Many ML applications rely for training and operation on (sometimes large volumes of) data about people. As in any software application, this data should be handled with care, as stipulated by privacy regulations (e.g. GDPR), information security standards, and ethical criteria. Specifically for ML-applications, privacy risk may occur because of pooling data from different sources, sharing data sets for training, and deploying models trained with personal data. Privacy-preserving techniques can be applied to mitigate these risks. #
applicability: Consider using privacy-preserving ML techniques whenever you are using data about people, especially in case of personally identifiable information. #
related: Other related practices #
dependencies: Similarities, differences and connections to other practices #
survey_question: 1 #
survey_item: We use privacy-preserving ML techniques (e.g. federated learning, differential privacy, or homomorphic encryption).

---

TODO

* Federated learning
* Differential privacy
* Homomorphic encryption
